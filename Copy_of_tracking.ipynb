{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buikhanhhung/Detection-and-tracking-object-with-natural-language-processing-in-video/blob/main/Copy_of_tracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YmAbiT3C4sg",
        "outputId": "26cc91ea-a365-42e4-f537-550c0f42ecea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.6.0+cu124)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.117-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.117-py3-none-any.whl (984 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m984.2/984.2 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.117 ultralytics-thop-2.0.14\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (7.7.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.14)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.7)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (5.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.3.7)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (1.17.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.24.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.13.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi\n",
            "Successfully installed jedi-0.19.2\n",
            "Requirement already satisfied: google-colab in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: google-auth==2.38.0 in /usr/local/lib/python3.11/dist-packages (from google-colab) (2.38.0)\n",
            "Requirement already satisfied: ipykernel==6.17.1 in /usr/local/lib/python3.11/dist-packages (from google-colab) (6.17.1)\n",
            "Requirement already satisfied: ipyparallel==8.8.0 in /usr/local/lib/python3.11/dist-packages (from google-colab) (8.8.0)\n",
            "Requirement already satisfied: ipython==7.34.0 in /usr/local/lib/python3.11/dist-packages (from google-colab) (7.34.0)\n",
            "Requirement already satisfied: notebook==6.5.7 in /usr/local/lib/python3.11/dist-packages (from google-colab) (6.5.7)\n",
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.11/dist-packages (from google-colab) (2.2.2)\n",
            "Requirement already satisfied: portpicker==1.5.2 in /usr/local/lib/python3.11/dist-packages (from google-colab) (1.5.2)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from google-colab) (2.32.3)\n",
            "Requirement already satisfied: tornado==6.4.2 in /usr/local/lib/python3.11/dist-packages (from google-colab) (6.4.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth==2.38.0->google-colab) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth==2.38.0->google-colab) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth==2.38.0->google-colab) (4.9.1)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (24.0.1)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (5.7.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipyparallel==8.8.0->google-colab) (4.4.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from ipyparallel==8.8.0->google-colab) (0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from ipyparallel==8.8.0->google-colab) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from ipyparallel==8.8.0->google-colab) (4.67.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (0.19.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (4.9.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (3.1.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (5.7.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (0.2.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2->google-colab) (2.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2->google-colab) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2->google-colab) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->google-colab) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->google-colab) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->google-colab) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->google-colab) (2025.1.31)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython==7.34.0->google-colab) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.1->notebook==6.5.7->google-colab) (4.3.7)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook==6.5.7->google-colab) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook==6.5.7->google-colab) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook==6.5.7->google-colab) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook==6.5.7->google-colab) (4.23.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython==7.34.0->google-colab) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.34.0->google-colab) (0.2.13)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth==2.38.0->google-colab) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.1->ipyparallel==8.8.0->google-colab) (1.17.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook==6.5.7->google-colab) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook==6.5.7->google-colab) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook==6.5.7->google-colab) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.7->google-colab) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.7->google-colab) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.7->google-colab) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.7->google-colab) (0.24.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.7->google-colab) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook==6.5.7->google-colab) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook==6.5.7->google-colab) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook==6.5.7->google-colab) (4.13.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook==6.5.7->google-colab) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.7->google-colab) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.7->google-colab) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.7->google-colab) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python\n",
        "!pip install numpy\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install transformers\n",
        "!pip install Pillow\n",
        "!pip install ultralytics\n",
        "!pip install ipywidgets\n",
        "!pip install google-colab\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d1ebd4bcd34242ccbc510d78b865144f",
            "1bd51c0cae8740f692b1b43c0f60dd6e",
            "45ca33753dfd4a0d9ef6621b7782aceb",
            "3f2118fac97e4159ab8a7fa0102aca87",
            "dbf354bbbff3406c9a98ad69909544ab",
            "80cf565cf4d3450db82b429c159e8909",
            "d660a580bc724763aa6c776ee602169b",
            "c8537fdd5f0d40ecaf767ca660f31937",
            "bf839712ad574fdea64303d416cff76d",
            "65abba2b2fed4982923e477566258b87",
            "8197a97e51aa4eb3b4ee9104775ebb78",
            "3e7d467e6e6b4dd391e2a0a3a64e26b4",
            "5e6c7c2900db4635bcbddaea6284e3b2",
            "ba312a1c56dd4cc1aec27c654d2b97f8",
            "92f1956248bc439398785445a82a50ab",
            "0c06ecd69377459383b5f0ba65d574a8",
            "b2f3699799ba4cc9a56d5cd170aceb30",
            "445439c979564c399826d5d6e64c55c8",
            "2e7eaa35d6254c4a96cc88f560c2075b",
            "8e05dba349854d0e82f2166e58f76e82",
            "6988020cb7574cd5bce9ab423028afa4",
            "a1a27775d5c649a4b8f6a372f8fb538c",
            "68b112836aac499eb8e6927984a12c34",
            "a343752a61fc471195863c1fdd442682",
            "94705c701d264e7b8f1eedd7e2b8cb01",
            "9f06a09a916d4b208d77c00f278a2bf1",
            "c716da8dcefe42bcbbf61278882bf357",
            "5f644ed5b67242a4bf1f3c479ec9ccc1",
            "c06feaa09c0d434b8bdefd02c3a3885a",
            "64d742e82a324d5b9eaa299ff44f6efd",
            "bc4d3084afa84f578b37291a3d72efe4",
            "99e6ef8c802f4d7dbf033ee590e04133",
            "091c1dfd56994c23aab32a4a254aab2a",
            "db94d541b390493a9119cd946e1cb94d",
            "59ad8f216d294aebacbd123f12993540",
            "69094fb36a2b498a86e4aa49a3a3b685",
            "4df1df4cacc34567981dc0d15b6b2fbe",
            "2309eea25da9474c876efebc14b4a767",
            "70ec960296ed4afdb33dbb89ba511478",
            "515adf57386b4f9cb6e751da8b05106d",
            "a9991cd01e9e46a2b7c3501de24b482a",
            "74a46231c19b4f2a9a58b25361a1bb8d",
            "ec26ae7fd2bb40d28f1b3fc69f293903",
            "1e9793c081044d8cb72a3c7691d1d2c4",
            "3beef3208daf4a859faa28e2323f612a",
            "b019145b970d4bb690fd66e2c753630a",
            "ec2a9201474f49ac941266497c532b76",
            "d61d96bd8e064d86b9fd4f6fb2af5013",
            "ab96e57dc414434fb417779b63cad442",
            "3f10a267ccaa407e98af0afc4c6dfb56",
            "41cedcecc6ca49f68b54dbe04879e248",
            "9f1d0c5306554e069cc2c3147f0676b8",
            "e116fd27008c4b44aef610d8eaf388f3",
            "9442e7e5f7dc4128ba66a2f86d67e411",
            "eb68b90822724eaba381eaf9fb9459dd",
            "56802f58ce934563bcf84443d12145ec",
            "cdfd713baa3d4e4faf39f8b472a4d1fb",
            "7c70b0c9f1224c2e8165502f822dfa2e",
            "11cbc9d4a02a43f298b547caba151d95",
            "2451169792da4c9ea22694bbd98041a7",
            "6daa2b736c164922aeb678a2108557ae",
            "3a783e0967194f62a92be1d9b387e275",
            "4f343239f9114f719e266944b593daa7",
            "ccbebac1f03043a28938ae4ea51797f0",
            "217500d7b5b040c5a3d8898f99b9e4bb",
            "fe9e7c997970480bbaf38c693daf828f",
            "c7701691ea354612a2dd5cce446d62ad",
            "170e9dcda6b348748a8026ae60339ea2",
            "2d7372bce5f44c4ea798804c7bf49315",
            "dc5b0aea26f54226b5fde49d40b1cdb3",
            "b013c13fccd44f408a86547d866dc463",
            "fe8e636a776d41a0a5d99e8e42a611a0",
            "d81aaf4c93dc491eabe17b56fecb377d",
            "2910fd85232e4cb1bdfb9cd23f1b8c75",
            "813e3b5fcc3244b18d9bf79b38cd26d2",
            "383c875985794aad97e9bbc28a3b467c",
            "ec2883482a9a4b1d987b7d655b4980ce",
            "8db337d20a8c4925857215a98b98c2e5",
            "c63e3001d764411e9df2e7600319f03d",
            "8f60445bed5a4ff29390fc057a496705",
            "ce0ce49a91af4db0961ad9fb7533ed68",
            "8341321f84514545ba0b9b0b57fac6bf",
            "780ad657c06d4a42b57de668f2755614",
            "f000113c2f264fffb570b1b69c499425",
            "ca8d3e199cd946f2b71a2a13798a09a0",
            "215c4881f20f444db4be5e43fe1b5ae4",
            "239c9ab6a9d74c92a87d16ca9c82fade",
            "9c9b95983a204be6a74892aa4b7c663f",
            "487a38fb1538444c8d5752aeaa89cb86",
            "90621a42cf504265a6fdfaac997fd67f",
            "6406ba75bdc84135aa784a2e65559030",
            "3d8993954a8349dc85a9268bc5b1aa0a",
            "d88c6a1fce1449e0ba5ff2f7118a9656",
            "e9fe9ac567784c7d8c93ec9392616fd1",
            "f29b5f1a341c4d8998901a27a40bc2fc",
            "5a21215111cb4dadbe5f6765d6c0b124",
            "14e361b595394ae6b8a34d094fa26cd3",
            "18cb6236cfaa4dd4ab4ac583a09ce09a",
            "169107a648684c4f8836dd33cf12b512"
          ]
        },
        "id": "jcAeYxg0C4sj",
        "outputId": "8d6d3765-36fb-4803-9d75-312aca7fc31c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21.5M/21.5M [00:00<00:00, 83.2MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1ebd4bcd34242ccbc510d78b865144f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e7d467e6e6b4dd391e2a0a3a64e26b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68b112836aac499eb8e6927984a12c34",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/605M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db94d541b390493a9119cd946e1cb94d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3beef3208daf4a859faa28e2323f612a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56802f58ce934563bcf84443d12145ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/862k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7701691ea354612a2dd5cce446d62ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8db337d20a8c4925857215a98b98c2e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "487a38fb1538444c8d5752aeaa89cb86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vui lòng tải lên một video.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d635dd1e-b66e-4a2e-9194-c871ca7c6b8b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d635dd1e-b66e-4a2e-9194-c871ca7c6b8b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving people.webm to people.webm\n",
            "File people.webm đã được lưu tại: /content/people.webm\n",
            "\n",
            "0: 384x640 20 persons, 1 car, 1 motorcycle, 436.3ms\n",
            "Speed: 8.4ms preprocess, 436.3ms inference, 21.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 cars, 1 motorcycle, 330.0ms\n",
            "Speed: 3.7ms preprocess, 330.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 car, 1 motorcycle, 612.9ms\n",
            "Speed: 3.5ms preprocess, 612.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 car, 1 motorcycle, 334.5ms\n",
            "Speed: 3.8ms preprocess, 334.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 bicycle, 2 cars, 1 motorcycle, 327.0ms\n",
            "Speed: 3.4ms preprocess, 327.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 2 cars, 2 motorcycles, 312.5ms\n",
            "Speed: 3.1ms preprocess, 312.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 3 motorcycles, 315.1ms\n",
            "Speed: 3.8ms preprocess, 315.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 car, 1 motorcycle, 325.4ms\n",
            "Speed: 4.6ms preprocess, 325.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 car, 1 motorcycle, 322.3ms\n",
            "Speed: 4.4ms preprocess, 322.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 car, 1 motorcycle, 314.9ms\n",
            "Speed: 3.6ms preprocess, 314.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 car, 1 motorcycle, 460.7ms\n",
            "Speed: 3.9ms preprocess, 460.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 car, 2 motorcycles, 305.7ms\n",
            "Speed: 3.7ms preprocess, 305.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 322.9ms\n",
            "Speed: 4.4ms preprocess, 322.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 cars, 1 motorcycle, 339.4ms\n",
            "Speed: 4.4ms preprocess, 339.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 car, 1 motorcycle, 313.8ms\n",
            "Speed: 3.7ms preprocess, 313.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 car, 1 motorcycle, 312.4ms\n",
            "Speed: 4.5ms preprocess, 312.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 bicycle, 1 car, 1 motorcycle, 326.5ms\n",
            "Speed: 3.5ms preprocess, 326.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 car, 2 motorcycles, 305.5ms\n",
            "Speed: 4.6ms preprocess, 305.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 car, 2 motorcycles, 310.3ms\n",
            "Speed: 4.4ms preprocess, 310.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 car, 1 motorcycle, 306.7ms\n",
            "Speed: 6.4ms preprocess, 306.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 car, 1 motorcycle, 488.1ms\n",
            "Speed: 3.8ms preprocess, 488.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 car, 1 motorcycle, 313.2ms\n",
            "Speed: 3.5ms preprocess, 313.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 bicycles, 1 car, 1 motorcycle, 1 backpack, 305.4ms\n",
            "Speed: 4.6ms preprocess, 305.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 2 cars, 1 motorcycle, 321.8ms\n",
            "Speed: 4.1ms preprocess, 321.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 bicycle, 2 cars, 1 motorcycle, 492.4ms\n",
            "Speed: 5.2ms preprocess, 492.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 cars, 1 motorcycle, 311.7ms\n",
            "Speed: 4.5ms preprocess, 311.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 2 cars, 1 motorcycle, 324.2ms\n",
            "Speed: 4.5ms preprocess, 324.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 cars, 1 motorcycle, 1 bus, 313.4ms\n",
            "Speed: 3.5ms preprocess, 313.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 car, 1 motorcycle, 1 truck, 308.5ms\n",
            "Speed: 3.8ms preprocess, 308.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 car, 1 motorcycle, 1 truck, 309.3ms\n",
            "Speed: 2.9ms preprocess, 309.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 1 car, 1 motorcycle, 1 truck, 311.3ms\n",
            "Speed: 3.8ms preprocess, 311.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 2 cars, 1 motorcycle, 1 truck, 500.1ms\n",
            "Speed: 3.7ms preprocess, 500.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 car, 1 motorcycle, 309.4ms\n",
            "Speed: 4.7ms preprocess, 309.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 car, 1 motorcycle, 310.0ms\n",
            "Speed: 5.5ms preprocess, 310.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 bicycle, 1 car, 1 motorcycle, 312.6ms\n",
            "Speed: 4.5ms preprocess, 312.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 car, 1 motorcycle, 313.7ms\n",
            "Speed: 4.4ms preprocess, 313.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 car, 1 motorcycle, 1 truck, 315.2ms\n",
            "Speed: 4.6ms preprocess, 315.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 car, 1 motorcycle, 314.5ms\n",
            "Speed: 3.7ms preprocess, 314.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 car, 1 motorcycle, 316.1ms\n",
            "Speed: 3.6ms preprocess, 316.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 car, 1 motorcycle, 314.6ms\n",
            "Speed: 4.8ms preprocess, 314.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 car, 1 motorcycle, 320.0ms\n",
            "Speed: 3.5ms preprocess, 320.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 1 motorcycle, 325.1ms\n",
            "Speed: 3.4ms preprocess, 325.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 car, 1 motorcycle, 313.2ms\n",
            "Speed: 4.6ms preprocess, 313.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 car, 1 motorcycle, 305.2ms\n",
            "Speed: 4.8ms preprocess, 305.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 car, 1 motorcycle, 310.7ms\n",
            "Speed: 3.3ms preprocess, 310.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 car, 1 motorcycle, 321.2ms\n",
            "Speed: 5.6ms preprocess, 321.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 338.6ms\n",
            "Speed: 3.5ms preprocess, 338.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 310.9ms\n",
            "Speed: 4.4ms preprocess, 310.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 1 motorcycle, 310.3ms\n",
            "Speed: 3.9ms preprocess, 310.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 car, 2 motorcycles, 310.4ms\n",
            "Speed: 3.1ms preprocess, 310.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 car, 3 motorcycles, 374.8ms\n",
            "Speed: 3.7ms preprocess, 374.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 3 motorcycles, 310.8ms\n",
            "Speed: 4.4ms preprocess, 310.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 2 motorcycles, 309.3ms\n",
            "Speed: 3.4ms preprocess, 309.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 3 bicycles, 1 car, 2 motorcycles, 307.2ms\n",
            "Speed: 3.4ms preprocess, 307.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 bicycle, 2 cars, 2 motorcycles, 311.5ms\n",
            "Speed: 3.4ms preprocess, 311.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 bicycle, 1 car, 1 motorcycle, 312.3ms\n",
            "Speed: 3.9ms preprocess, 312.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 317.2ms\n",
            "Speed: 3.8ms preprocess, 317.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 329.5ms\n",
            "Speed: 3.4ms preprocess, 329.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 1 motorcycle, 316.3ms\n",
            "Speed: 4.7ms preprocess, 316.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 bicycles, 1 car, 1 motorcycle, 313.5ms\n",
            "Speed: 3.7ms preprocess, 313.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 1 bicycle, 1 car, 1 motorcycle, 324.8ms\n",
            "Speed: 3.5ms preprocess, 324.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 bicycle, 1 car, 1 motorcycle, 533.9ms\n",
            "Speed: 3.8ms preprocess, 533.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 1 motorcycle, 309.6ms\n",
            "Speed: 3.4ms preprocess, 309.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 1 motorcycle, 322.1ms\n",
            "Speed: 4.3ms preprocess, 322.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 bicycle, 1 car, 1 motorcycle, 317.2ms\n",
            "Speed: 3.7ms preprocess, 317.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 bicycle, 1 car, 1 motorcycle, 310.1ms\n",
            "Speed: 3.7ms preprocess, 310.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 bicycle, 1 car, 1 motorcycle, 318.9ms\n",
            "Speed: 3.7ms preprocess, 318.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 bicycles, 1 car, 1 motorcycle, 321.3ms\n",
            "Speed: 4.4ms preprocess, 321.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 1 bicycle, 1 car, 1 motorcycle, 501.0ms\n",
            "Speed: 3.6ms preprocess, 501.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 bicycle, 1 car, 1 motorcycle, 304.1ms\n",
            "Speed: 3.0ms preprocess, 304.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 2 bicycles, 1 car, 1 motorcycle, 308.6ms\n",
            "Speed: 3.7ms preprocess, 308.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 bicycle, 1 car, 1 motorcycle, 314.8ms\n",
            "Speed: 3.4ms preprocess, 314.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 bicycles, 1 car, 1 motorcycle, 314.0ms\n",
            "Speed: 4.4ms preprocess, 314.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 314.0ms\n",
            "Speed: 3.3ms preprocess, 314.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bicycle, 1 car, 1 motorcycle, 313.8ms\n",
            "Speed: 2.8ms preprocess, 313.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 495.3ms\n",
            "Speed: 3.5ms preprocess, 495.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 bicycles, 1 car, 1 motorcycle, 311.1ms\n",
            "Speed: 4.5ms preprocess, 311.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 bicycles, 1 car, 1 motorcycle, 304.4ms\n",
            "Speed: 3.6ms preprocess, 304.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 342.8ms\n",
            "Speed: 3.4ms preprocess, 342.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 1 motorcycle, 312.1ms\n",
            "Speed: 3.2ms preprocess, 312.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 305.1ms\n",
            "Speed: 4.3ms preprocess, 305.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 323.1ms\n",
            "Speed: 3.6ms preprocess, 323.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 bicycle, 1 car, 1 motorcycle, 354.8ms\n",
            "Speed: 4.0ms preprocess, 354.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 325.8ms\n",
            "Speed: 4.3ms preprocess, 325.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 bicycles, 1 car, 1 motorcycle, 308.3ms\n",
            "Speed: 3.8ms preprocess, 308.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 bicycles, 1 car, 1 motorcycle, 310.7ms\n",
            "Speed: 4.0ms preprocess, 310.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 1 motorcycle, 323.2ms\n",
            "Speed: 4.9ms preprocess, 323.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 1 motorcycle, 311.0ms\n",
            "Speed: 3.4ms preprocess, 311.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 1 motorcycle, 344.9ms\n",
            "Speed: 7.2ms preprocess, 344.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 324.0ms\n",
            "Speed: 3.5ms preprocess, 324.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 329.4ms\n",
            "Speed: 5.1ms preprocess, 329.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 319.7ms\n",
            "Speed: 4.8ms preprocess, 319.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 326.4ms\n",
            "Speed: 3.6ms preprocess, 326.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 bicycle, 1 car, 1 motorcycle, 311.6ms\n",
            "Speed: 4.0ms preprocess, 311.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 1 motorcycle, 323.2ms\n",
            "Speed: 4.5ms preprocess, 323.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 2 bicycles, 1 car, 1 motorcycle, 312.3ms\n",
            "Speed: 3.0ms preprocess, 312.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 2 bicycles, 1 car, 1 motorcycle, 312.7ms\n",
            "Speed: 4.5ms preprocess, 312.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 2 bicycles, 1 car, 321.8ms\n",
            "Speed: 4.0ms preprocess, 321.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 bicycles, 1 car, 320.1ms\n",
            "Speed: 5.4ms preprocess, 320.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 bicycles, 1 car, 311.6ms\n",
            "Speed: 5.0ms preprocess, 311.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 bicycles, 1 car, 308.3ms\n",
            "Speed: 3.6ms preprocess, 308.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 bicycles, 1 car, 509.1ms\n",
            "Speed: 4.6ms preprocess, 509.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 bicycles, 1 car, 312.0ms\n",
            "Speed: 3.8ms preprocess, 312.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 bicycles, 1 car, 304.9ms\n",
            "Speed: 3.4ms preprocess, 304.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 bicycles, 1 car, 2 handbags, 506.9ms\n",
            "Speed: 3.6ms preprocess, 506.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 2 bicycles, 1 car, 321.7ms\n",
            "Speed: 6.8ms preprocess, 321.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 bicycles, 1 car, 1 motorcycle, 2 handbags, 314.7ms\n",
            "Speed: 3.4ms preprocess, 314.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 3 bicycles, 1 car, 1 handbag, 510.5ms\n",
            "Speed: 3.6ms preprocess, 510.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 2 bicycles, 2 cars, 1 motorcycle, 1 handbag, 324.4ms\n",
            "Speed: 4.7ms preprocess, 324.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 2 bicycles, 1 car, 1 motorcycle, 1 handbag, 308.6ms\n",
            "Speed: 2.8ms preprocess, 308.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 3 bicycles, 1 car, 328.3ms\n",
            "Speed: 3.3ms preprocess, 328.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 2 bicycles, 1 car, 1 motorcycle, 1 handbag, 321.9ms\n",
            "Speed: 3.6ms preprocess, 321.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 bicycles, 1 car, 2 motorcycles, 2 handbags, 304.9ms\n",
            "Speed: 3.5ms preprocess, 304.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 bicycle, 1 car, 2 motorcycles, 1 handbag, 320.3ms\n",
            "Speed: 3.6ms preprocess, 320.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 2 bicycles, 1 car, 3 motorcycles, 429.1ms\n",
            "Speed: 3.9ms preprocess, 429.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 2 bicycles, 1 car, 1 motorcycle, 314.7ms\n",
            "Speed: 4.3ms preprocess, 314.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 1 bicycle, 1 car, 3 motorcycles, 317.0ms\n",
            "Speed: 4.1ms preprocess, 317.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 bicycle, 1 car, 1 motorcycle, 1 handbag, 320.4ms\n",
            "Speed: 3.1ms preprocess, 320.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 bicycle, 1 car, 2 motorcycles, 1 handbag, 332.3ms\n",
            "Speed: 5.5ms preprocess, 332.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 1 bicycle, 1 car, 2 motorcycles, 1 handbag, 328.6ms\n",
            "Speed: 4.7ms preprocess, 328.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 1 bicycle, 1 car, 3 motorcycles, 308.6ms\n",
            "Speed: 3.4ms preprocess, 308.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 bicycle, 1 car, 2 motorcycles, 309.4ms\n",
            "Speed: 3.6ms preprocess, 309.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 2 bicycles, 1 car, 2 motorcycles, 326.1ms\n",
            "Speed: 3.8ms preprocess, 326.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 bicycle, 1 car, 2 motorcycles, 514.6ms\n",
            "Speed: 3.5ms preprocess, 514.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 1 bicycle, 1 car, 2 motorcycles, 323.8ms\n",
            "Speed: 4.2ms preprocess, 323.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 3 bicycles, 1 car, 2 motorcycles, 315.4ms\n",
            "Speed: 3.9ms preprocess, 315.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 bicycle, 1 car, 2 motorcycles, 308.6ms\n",
            "Speed: 3.5ms preprocess, 308.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 bicycle, 1 car, 1 motorcycle, 324.2ms\n",
            "Speed: 4.8ms preprocess, 324.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 bicycle, 1 car, 2 motorcycles, 324.8ms\n",
            "Speed: 4.2ms preprocess, 324.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 bicycle, 1 car, 1 motorcycle, 307.0ms\n",
            "Speed: 3.5ms preprocess, 307.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 1 bicycle, 1 car, 1 motorcycle, 309.5ms\n",
            "Speed: 3.8ms preprocess, 309.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 1 bicycle, 1 car, 2 motorcycles, 1 handbag, 310.3ms\n",
            "Speed: 3.3ms preprocess, 310.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 bicycle, 1 car, 1 motorcycle, 1 handbag, 467.8ms\n",
            "Speed: 3.5ms preprocess, 467.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 1 bicycle, 1 car, 1 motorcycle, 315.2ms\n",
            "Speed: 3.8ms preprocess, 315.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 bicycle, 1 car, 1 motorcycle, 324.4ms\n",
            "Speed: 4.6ms preprocess, 324.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 1 bicycle, 1 car, 1 motorcycle, 496.4ms\n",
            "Speed: 3.5ms preprocess, 496.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 1 bicycle, 1 car, 1 motorcycle, 1 suitcase, 315.5ms\n",
            "Speed: 4.7ms preprocess, 315.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 bicycle, 1 car, 1 motorcycle, 1 handbag, 307.6ms\n",
            "Speed: 3.6ms preprocess, 307.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 bicycle, 1 car, 1 motorcycle, 507.7ms\n",
            "Speed: 3.8ms preprocess, 507.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 1 bicycle, 1 car, 2 motorcycles, 308.6ms\n",
            "Speed: 3.6ms preprocess, 308.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 bicycle, 1 car, 2 motorcycles, 1 handbag, 313.9ms\n",
            "Speed: 3.4ms preprocess, 313.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 bicycle, 1 car, 2 motorcycles, 325.6ms\n",
            "Speed: 5.8ms preprocess, 325.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 bicycle, 1 car, 3 motorcycles, 308.3ms\n",
            "Speed: 3.5ms preprocess, 308.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 bicycle, 1 car, 3 motorcycles, 320.8ms\n",
            "Speed: 4.9ms preprocess, 320.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 3 bicycles, 1 car, 2 motorcycles, 316.6ms\n",
            "Speed: 3.8ms preprocess, 316.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 3 bicycles, 1 car, 2 motorcycles, 311.6ms\n",
            "Speed: 3.4ms preprocess, 311.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 3 bicycles, 1 car, 2 motorcycles, 318.1ms\n",
            "Speed: 4.8ms preprocess, 318.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 3 bicycles, 1 car, 2 motorcycles, 312.0ms\n",
            "Speed: 4.1ms preprocess, 312.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 3 bicycles, 1 car, 1 motorcycle, 311.6ms\n",
            "Speed: 4.1ms preprocess, 311.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 3 bicycles, 1 car, 1 motorcycle, 325.8ms\n",
            "Speed: 3.5ms preprocess, 325.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 3 bicycles, 1 car, 1 motorcycle, 313.6ms\n",
            "Speed: 3.7ms preprocess, 313.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 3 bicycles, 1 car, 1 handbag, 319.6ms\n",
            "Speed: 3.2ms preprocess, 319.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 3 bicycles, 1 car, 1 motorcycle, 321.3ms\n",
            "Speed: 3.6ms preprocess, 321.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 bicycles, 1 car, 307.2ms\n",
            "Speed: 4.8ms preprocess, 307.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 3 bicycles, 1 car, 311.6ms\n",
            "Speed: 4.4ms preprocess, 311.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 2 bicycles, 1 car, 320.4ms\n",
            "Speed: 3.5ms preprocess, 320.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 bicycles, 1 car, 1 motorcycle, 2 handbags, 313.8ms\n",
            "Speed: 4.0ms preprocess, 313.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 2 bicycles, 1 car, 1 motorcycle, 325.5ms\n",
            "Speed: 4.8ms preprocess, 325.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 2 bicycles, 1 car, 1 motorcycle, 323.8ms\n",
            "Speed: 4.0ms preprocess, 323.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 2 bicycles, 1 car, 1 motorcycle, 504.2ms\n",
            "Speed: 3.9ms preprocess, 504.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 2 bicycles, 1 car, 1 motorcycle, 313.2ms\n",
            "Speed: 3.9ms preprocess, 313.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 1 bicycle, 1 car, 3 motorcycles, 308.7ms\n",
            "Speed: 3.0ms preprocess, 308.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 1 bicycle, 1 car, 3 motorcycles, 401.1ms\n",
            "Speed: 4.0ms preprocess, 401.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 1 bicycle, 1 car, 2 motorcycles, 306.9ms\n",
            "Speed: 3.3ms preprocess, 306.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 bicycle, 1 car, 1 motorcycle, 314.8ms\n",
            "Speed: 4.9ms preprocess, 314.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 bicycle, 1 car, 1 motorcycle, 312.8ms\n",
            "Speed: 4.3ms preprocess, 312.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 1 bicycle, 1 car, 1 motorcycle, 323.2ms\n",
            "Speed: 3.5ms preprocess, 323.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 bicycle, 1 car, 1 motorcycle, 305.8ms\n",
            "Speed: 3.5ms preprocess, 305.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 bicycle, 1 car, 1 handbag, 307.7ms\n",
            "Speed: 3.5ms preprocess, 307.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 bicycle, 1 car, 1 motorcycle, 1 handbag, 320.8ms\n",
            "Speed: 4.4ms preprocess, 320.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 bicycle, 1 car, 1 motorcycle, 1 handbag, 330.4ms\n",
            "Speed: 3.6ms preprocess, 330.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 bicycle, 1 car, 2 motorcycles, 515.9ms\n",
            "Speed: 7.8ms preprocess, 515.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 bicycles, 1 car, 2 motorcycles, 311.1ms\n",
            "Speed: 3.8ms preprocess, 311.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 bicycles, 1 car, 2 motorcycles, 310.5ms\n",
            "Speed: 4.0ms preprocess, 310.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 bicycles, 1 car, 2 motorcycles, 322.9ms\n",
            "Speed: 4.9ms preprocess, 322.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 bicycles, 1 car, 2 motorcycles, 311.8ms\n",
            "Speed: 4.4ms preprocess, 311.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 bicycle, 1 car, 2 motorcycles, 1 handbag, 309.6ms\n",
            "Speed: 3.5ms preprocess, 309.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 1 bicycle, 1 car, 2 motorcycles, 1 handbag, 313.8ms\n",
            "Speed: 3.5ms preprocess, 313.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 1 bicycle, 1 car, 2 motorcycles, 331.4ms\n",
            "Speed: 2.8ms preprocess, 331.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 bicycle, 1 car, 2 motorcycles, 310.1ms\n",
            "Speed: 4.6ms preprocess, 310.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 1 bicycle, 1 car, 2 motorcycles, 1 handbag, 320.6ms\n",
            "Speed: 3.5ms preprocess, 320.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 1 bicycle, 1 car, 2 motorcycles, 1 handbag, 308.0ms\n",
            "Speed: 5.1ms preprocess, 308.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 bicycle, 1 car, 3 motorcycles, 312.5ms\n",
            "Speed: 3.4ms preprocess, 312.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 bicycle, 1 car, 3 motorcycles, 307.4ms\n",
            "Speed: 3.5ms preprocess, 307.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 1 bicycle, 1 car, 2 motorcycles, 307.3ms\n",
            "Speed: 3.8ms preprocess, 307.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 1 bicycle, 1 car, 1 motorcycle, 320.5ms\n",
            "Speed: 3.6ms preprocess, 320.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 1 bicycle, 1 car, 2 motorcycles, 313.6ms\n",
            "Speed: 3.2ms preprocess, 313.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 1 bicycle, 1 car, 2 motorcycles, 315.8ms\n",
            "Speed: 5.5ms preprocess, 315.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 1 bicycle, 1 car, 3 motorcycles, 314.5ms\n",
            "Speed: 3.6ms preprocess, 314.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 bicycle, 1 car, 3 motorcycles, 325.0ms\n",
            "Speed: 3.1ms preprocess, 325.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 1 bicycle, 1 car, 2 motorcycles, 323.1ms\n",
            "Speed: 3.4ms preprocess, 323.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 1 bicycle, 1 car, 3 motorcycles, 514.1ms\n",
            "Speed: 7.2ms preprocess, 514.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 bicycle, 1 car, 3 motorcycles, 321.0ms\n",
            "Speed: 3.5ms preprocess, 321.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 1 bicycle, 1 car, 2 motorcycles, 304.2ms\n",
            "Speed: 3.5ms preprocess, 304.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 1 bicycle, 1 car, 3 motorcycles, 434.5ms\n",
            "Speed: 3.5ms preprocess, 434.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 1 bicycle, 1 car, 2 motorcycles, 310.9ms\n",
            "Speed: 4.1ms preprocess, 310.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 1 bicycle, 1 car, 1 motorcycle, 328.1ms\n",
            "Speed: 3.8ms preprocess, 328.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 bicycle, 1 car, 1 motorcycle, 1 backpack, 315.5ms\n",
            "Speed: 5.8ms preprocess, 315.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 bicycle, 1 car, 1 motorcycle, 316.9ms\n",
            "Speed: 4.5ms preprocess, 316.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 bicycle, 1 car, 1 motorcycle, 310.3ms\n",
            "Speed: 5.1ms preprocess, 310.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 bicycle, 1 car, 1 motorcycle, 311.2ms\n",
            "Speed: 3.2ms preprocess, 311.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 1 bicycle, 1 car, 1 motorcycle, 305.1ms\n",
            "Speed: 5.1ms preprocess, 305.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 bicycle, 1 car, 1 motorcycle, 312.1ms\n",
            "Speed: 3.5ms preprocess, 312.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 1 bicycle, 1 car, 1 motorcycle, 331.4ms\n",
            "Speed: 3.6ms preprocess, 331.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 bicycle, 1 car, 1 motorcycle, 308.0ms\n",
            "Speed: 3.5ms preprocess, 308.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 1 motorcycle, 308.4ms\n",
            "Speed: 3.4ms preprocess, 308.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 bicycles, 1 car, 1 motorcycle, 330.4ms\n",
            "Speed: 5.0ms preprocess, 330.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 bicycle, 1 car, 1 motorcycle, 313.6ms\n",
            "Speed: 5.1ms preprocess, 313.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 bicycle, 1 car, 1 motorcycle, 309.9ms\n",
            "Speed: 4.2ms preprocess, 309.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 308.9ms\n",
            "Speed: 3.6ms preprocess, 308.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 310.9ms\n",
            "Speed: 4.6ms preprocess, 310.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 309.8ms\n",
            "Speed: 3.7ms preprocess, 309.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 1 handbag, 304.4ms\n",
            "Speed: 3.9ms preprocess, 304.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 2 handbags, 498.7ms\n",
            "Speed: 3.6ms preprocess, 498.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 1 motorcycle, 1 handbag, 323.6ms\n",
            "Speed: 4.1ms preprocess, 323.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 1 motorcycle, 321.8ms\n",
            "Speed: 4.6ms preprocess, 321.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 1 motorcycle, 313.3ms\n",
            "Speed: 3.5ms preprocess, 313.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bicycle, 1 car, 1 motorcycle, 327.3ms\n",
            "Speed: 4.9ms preprocess, 327.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 2 motorcycles, 309.7ms\n",
            "Speed: 3.5ms preprocess, 309.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bicycle, 1 car, 1 motorcycle, 314.6ms\n",
            "Speed: 3.1ms preprocess, 314.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 505.9ms\n",
            "Speed: 5.7ms preprocess, 505.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bicycle, 1 car, 2 motorcycles, 319.9ms\n",
            "Speed: 7.1ms preprocess, 319.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 1 motorcycle, 325.1ms\n",
            "Speed: 3.6ms preprocess, 325.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 309.1ms\n",
            "Speed: 3.9ms preprocess, 309.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 1 motorcycle, 326.5ms\n",
            "Speed: 3.6ms preprocess, 326.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 325.7ms\n",
            "Speed: 4.4ms preprocess, 325.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 bicycles, 1 car, 1 motorcycle, 326.5ms\n",
            "Speed: 3.7ms preprocess, 326.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 bicycles, 1 car, 1 motorcycle, 314.3ms\n",
            "Speed: 3.7ms preprocess, 314.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bicycle, 1 car, 1 motorcycle, 328.3ms\n",
            "Speed: 6.5ms preprocess, 328.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 1 motorcycle, 324.6ms\n",
            "Speed: 2.9ms preprocess, 324.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bicycle, 1 car, 1 motorcycle, 1 backpack, 322.8ms\n",
            "Speed: 3.5ms preprocess, 322.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bicycle, 1 car, 1 motorcycle, 493.5ms\n",
            "Speed: 6.6ms preprocess, 493.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bicycle, 2 cars, 2 motorcycles, 322.4ms\n",
            "Speed: 3.9ms preprocess, 322.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 2 cars, 2 motorcycles, 303.6ms\n",
            "Speed: 5.7ms preprocess, 303.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bicycle, 1 car, 2 motorcycles, 321.4ms\n",
            "Speed: 3.5ms preprocess, 321.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 1 car, 1 motorcycle, 423.6ms\n",
            "Speed: 14.1ms preprocess, 423.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bicycle, 2 cars, 1 motorcycle, 330.6ms\n",
            "Speed: 3.7ms preprocess, 330.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bicycle, 1 car, 1 motorcycle, 505.4ms\n",
            "Speed: 5.8ms preprocess, 505.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bicycle, 1 car, 1 motorcycle, 309.7ms\n",
            "Speed: 3.8ms preprocess, 309.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bicycle, 1 car, 1 motorcycle, 1 backpack, 312.6ms\n",
            "Speed: 5.0ms preprocess, 312.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 1 motorcycle, 1 backpack, 308.5ms\n",
            "Speed: 4.3ms preprocess, 308.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bicycle, 1 car, 2 motorcycles, 1 backpack, 427.1ms\n",
            "Speed: 3.7ms preprocess, 427.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 1 backpack, 309.5ms\n",
            "Speed: 3.9ms preprocess, 309.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bicycle, 1 car, 1 motorcycle, 308.3ms\n",
            "Speed: 5.6ms preprocess, 308.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bicycle, 1 car, 2 motorcycles, 307.3ms\n",
            "Speed: 5.0ms preprocess, 307.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bicycle, 1 car, 2 motorcycles, 316.0ms\n",
            "Speed: 4.4ms preprocess, 316.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bicycle, 1 car, 1 motorcycle, 317.1ms\n",
            "Speed: 3.9ms preprocess, 317.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 1 car, 1 motorcycle, 1 backpack, 310.9ms\n",
            "Speed: 5.1ms preprocess, 310.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bicycle, 1 car, 1 motorcycle, 504.2ms\n",
            "Speed: 3.7ms preprocess, 504.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bicycle, 1 car, 1 motorcycle, 325.4ms\n",
            "Speed: 3.5ms preprocess, 325.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bicycle, 1 car, 1 motorcycle, 310.1ms\n",
            "Speed: 4.7ms preprocess, 310.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bicycle, 1 car, 2 motorcycles, 308.9ms\n",
            "Speed: 3.7ms preprocess, 308.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bicycle, 1 car, 1 motorcycle, 491.8ms\n",
            "Speed: 3.8ms preprocess, 491.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bicycle, 1 car, 1 motorcycle, 309.5ms\n",
            "Speed: 3.1ms preprocess, 309.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 1 motorcycle, 319.6ms\n",
            "Speed: 4.2ms preprocess, 319.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bicycle, 1 car, 1 motorcycle, 310.3ms\n",
            "Speed: 3.7ms preprocess, 310.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bicycle, 1 car, 1 motorcycle, 376.0ms\n",
            "Speed: 3.6ms preprocess, 376.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 1 motorcycle, 325.0ms\n",
            "Speed: 3.5ms preprocess, 325.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bicycle, 1 car, 1 motorcycle, 309.4ms\n",
            "Speed: 3.6ms preprocess, 309.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 3 motorcycles, 329.0ms\n",
            "Speed: 4.2ms preprocess, 329.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 2 motorcycles, 314.9ms\n",
            "Speed: 3.6ms preprocess, 314.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 2 motorcycles, 386.6ms\n",
            "Speed: 7.6ms preprocess, 386.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 325.1ms\n",
            "Speed: 3.7ms preprocess, 325.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 2 motorcycles, 314.0ms\n",
            "Speed: 4.7ms preprocess, 314.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bicycle, 1 car, 1 motorcycle, 314.7ms\n",
            "Speed: 3.7ms preprocess, 314.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bicycle, 1 car, 1 motorcycle, 495.5ms\n",
            "Speed: 3.6ms preprocess, 495.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 322.4ms\n",
            "Speed: 3.6ms preprocess, 322.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 2 motorcycles, 312.2ms\n",
            "Speed: 6.4ms preprocess, 312.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 2 motorcycles, 323.6ms\n",
            "Speed: 4.0ms preprocess, 323.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 2 motorcycles, 489.4ms\n",
            "Speed: 3.8ms preprocess, 489.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 1 motorcycle, 310.5ms\n",
            "Speed: 3.6ms preprocess, 310.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 1 motorcycle, 312.8ms\n",
            "Speed: 3.6ms preprocess, 312.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 1 motorcycle, 312.3ms\n",
            "Speed: 3.6ms preprocess, 312.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 2 motorcycles, 309.5ms\n",
            "Speed: 4.7ms preprocess, 309.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 2 motorcycles, 313.9ms\n",
            "Speed: 3.5ms preprocess, 313.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 2 motorcycles, 311.0ms\n",
            "Speed: 3.7ms preprocess, 311.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 2 motorcycles, 325.1ms\n",
            "Speed: 4.7ms preprocess, 325.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 2 motorcycles, 309.4ms\n",
            "Speed: 4.4ms preprocess, 309.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bicycle, 1 car, 2 motorcycles, 306.0ms\n",
            "Speed: 3.6ms preprocess, 306.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 2 motorcycles, 308.1ms\n",
            "Speed: 3.5ms preprocess, 308.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 1 motorcycle, 321.4ms\n",
            "Speed: 3.8ms preprocess, 321.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bicycle, 1 car, 1 motorcycle, 310.8ms\n",
            "Speed: 3.6ms preprocess, 310.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 1 motorcycle, 311.9ms\n",
            "Speed: 4.4ms preprocess, 311.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bicycle, 1 car, 2 motorcycles, 513.0ms\n",
            "Speed: 3.6ms preprocess, 513.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 2 motorcycles, 312.6ms\n",
            "Speed: 3.7ms preprocess, 312.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 2 motorcycles, 311.9ms\n",
            "Speed: 3.3ms preprocess, 311.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 bicycle, 1 car, 2 motorcycles, 503.9ms\n",
            "Speed: 4.0ms preprocess, 503.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 bicycle, 1 car, 2 motorcycles, 312.9ms\n",
            "Speed: 3.7ms preprocess, 312.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 bicycles, 1 car, 1 motorcycle, 308.4ms\n",
            "Speed: 3.6ms preprocess, 308.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 bicycle, 1 car, 2 motorcycles, 319.6ms\n",
            "Speed: 3.1ms preprocess, 319.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 1 motorcycle, 310.0ms\n",
            "Speed: 3.6ms preprocess, 310.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 2 motorcycles, 325.7ms\n",
            "Speed: 4.0ms preprocess, 325.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 bicycle, 1 car, 1 motorcycle, 328.8ms\n",
            "Speed: 3.5ms preprocess, 328.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 1 motorcycle, 503.3ms\n",
            "Speed: 3.8ms preprocess, 503.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 bicycle, 1 car, 1 motorcycle, 317.5ms\n",
            "Speed: 4.1ms preprocess, 317.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 bicycle, 1 car, 1 motorcycle, 320.4ms\n",
            "Speed: 4.5ms preprocess, 320.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 bicycle, 1 car, 2 motorcycles, 517.8ms\n",
            "Speed: 3.8ms preprocess, 517.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 bicycle, 1 car, 3 motorcycles, 309.6ms\n",
            "Speed: 3.6ms preprocess, 309.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 2 bicycles, 1 car, 1 motorcycle, 307.7ms\n",
            "Speed: 3.7ms preprocess, 307.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 bicycle, 1 car, 1 motorcycle, 511.0ms\n",
            "Speed: 3.6ms preprocess, 511.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 2 motorcycles, 307.4ms\n",
            "Speed: 3.6ms preprocess, 307.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 2 motorcycles, 349.1ms\n",
            "Speed: 3.5ms preprocess, 349.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 bicycles, 1 car, 1 motorcycle, 505.8ms\n",
            "Speed: 6.0ms preprocess, 505.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 2 motorcycles, 326.1ms\n",
            "Speed: 6.4ms preprocess, 326.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 308.1ms\n",
            "Speed: 3.5ms preprocess, 308.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 1 motorcycle, 1 handbag, 499.2ms\n",
            "Speed: 5.5ms preprocess, 499.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 bicycle, 1 car, 3 motorcycles, 312.8ms\n",
            "Speed: 3.6ms preprocess, 312.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 3 motorcycles, 320.0ms\n",
            "Speed: 4.2ms preprocess, 320.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 bicycles, 1 car, 2 motorcycles, 310.8ms\n",
            "Speed: 3.6ms preprocess, 310.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 2 motorcycles, 307.6ms\n",
            "Speed: 3.5ms preprocess, 307.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 3 motorcycles, 1 handbag, 332.8ms\n",
            "Speed: 4.1ms preprocess, 332.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 3 motorcycles, 1 handbag, 312.6ms\n",
            "Speed: 3.6ms preprocess, 312.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 2 motorcycles, 1 handbag, 308.5ms\n",
            "Speed: 5.0ms preprocess, 308.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 2 motorcycles, 1 handbag, 319.5ms\n",
            "Speed: 3.8ms preprocess, 319.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 2 motorcycles, 1 handbag, 313.8ms\n",
            "Speed: 3.5ms preprocess, 313.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 bicycles, 2 cars, 2 motorcycles, 517.1ms\n",
            "Speed: 3.7ms preprocess, 517.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 2 motorcycles, 314.1ms\n",
            "Speed: 4.4ms preprocess, 314.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 2 motorcycles, 310.0ms\n",
            "Speed: 2.7ms preprocess, 310.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 bicycle, 1 car, 2 motorcycles, 462.3ms\n",
            "Speed: 5.4ms preprocess, 462.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 2 motorcycles, 1 handbag, 324.3ms\n",
            "Speed: 5.9ms preprocess, 324.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 1 motorcycle, 320.6ms\n",
            "Speed: 3.8ms preprocess, 320.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 2 motorcycles, 1 handbag, 311.0ms\n",
            "Speed: 3.7ms preprocess, 311.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 2 motorcycles, 306.9ms\n",
            "Speed: 3.7ms preprocess, 306.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 2 motorcycles, 1 handbag, 324.0ms\n",
            "Speed: 4.7ms preprocess, 324.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 4 motorcycles, 1 handbag, 304.1ms\n",
            "Speed: 3.7ms preprocess, 304.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 3 motorcycles, 1 handbag, 321.4ms\n",
            "Speed: 5.0ms preprocess, 321.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 3 motorcycles, 1 handbag, 317.4ms\n",
            "Speed: 3.7ms preprocess, 317.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 bicycles, 1 car, 2 motorcycles, 1 handbag, 313.2ms\n",
            "Speed: 5.9ms preprocess, 313.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 2 motorcycles, 373.8ms\n",
            "Speed: 3.8ms preprocess, 373.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bicycle, 1 car, 2 motorcycles, 312.4ms\n",
            "Speed: 3.9ms preprocess, 312.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bicycle, 1 car, 2 motorcycles, 305.7ms\n",
            "Speed: 3.9ms preprocess, 305.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 2 motorcycles, 493.8ms\n",
            "Speed: 3.9ms preprocess, 493.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bicycle, 1 car, 4 motorcycles, 1 handbag, 310.8ms\n",
            "Speed: 3.7ms preprocess, 310.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 bicycle, 1 car, 4 motorcycles, 2 handbags, 309.4ms\n",
            "Speed: 3.6ms preprocess, 309.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 1 car, 3 motorcycles, 1 handbag, 498.4ms\n",
            "Speed: 4.0ms preprocess, 498.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 bicycle, 1 car, 3 motorcycles, 2 handbags, 321.2ms\n",
            "Speed: 4.1ms preprocess, 321.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 3 motorcycles, 2 handbags, 322.0ms\n",
            "Speed: 4.7ms preprocess, 322.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 1 car, 3 motorcycles, 3 handbags, 308.8ms\n",
            "Speed: 3.7ms preprocess, 308.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 car, 5 motorcycles, 2 handbags, 317.5ms\n",
            "Speed: 3.6ms preprocess, 317.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 car, 4 motorcycles, 1 handbag, 319.4ms\n",
            "Speed: 4.5ms preprocess, 319.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 car, 2 motorcycles, 1 handbag, 325.3ms\n",
            "Speed: 4.1ms preprocess, 325.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 car, 3 motorcycles, 314.5ms\n",
            "Speed: 4.2ms preprocess, 314.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 car, 3 motorcycles, 305.0ms\n",
            "Speed: 3.5ms preprocess, 305.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 car, 4 motorcycles, 317.3ms\n",
            "Speed: 3.6ms preprocess, 317.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 bicycle, 1 car, 2 motorcycles, 307.4ms\n",
            "Speed: 4.7ms preprocess, 307.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 car, 2 motorcycles, 309.5ms\n",
            "Speed: 3.4ms preprocess, 309.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 car, 3 motorcycles, 313.8ms\n",
            "Speed: 3.6ms preprocess, 313.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 car, 3 motorcycles, 325.3ms\n",
            "Speed: 3.7ms preprocess, 325.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 car, 3 motorcycles, 1 handbag, 309.8ms\n",
            "Speed: 3.8ms preprocess, 309.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 car, 5 motorcycles, 309.5ms\n",
            "Speed: 3.1ms preprocess, 309.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Video đã được lưu tại output_video.mp4\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_c87bdad7-8097-40c9-92ba-1f01d0f601b3\", \"output_video.mp4\", 7783549)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import cv2  # Thư viện OpenCV để xử lý video và ảnh.\n",
        "import numpy as np  # Thư viện NumPy để xử lý dữ liệu số học.\n",
        "from transformers import CLIPProcessor, CLIPModel  # Thư viện Transformers để sử dụng mô hình CLIP.\n",
        "from PIL import Image  # Thư viện PIL để xử lý ảnh.\n",
        "import torch  # Thư viện PyTorch để sử dụng GPU và các mô hình AI.\n",
        "from ultralytics import YOLO  # Thư viện YOLO để phát hiện đối tượng.\n",
        "from google.colab import files  # Công cụ hỗ trợ tải file lên/xuống trong Google Colab.\n",
        "import os  # Thư viện xử lý các tác vụ liên quan đến hệ thống tệp.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Phương pháp phát hiện và theo dõi đối tượng:\n",
        "Bước 1: Lấy từng khung hình trong video\n",
        "Bước 2: Phát hiện các đối tượng trong khung hình bằng YOLOv8\n",
        "Bước 3: Kết hợp các đối tượng đã phát hiện ở bước 2 với mô tả ngôn ngữ tự nhiên bằng CLIP\n",
        "Bước 4: Chọn đối tượng có độ tương thích cao nhất\n",
        "Bước 5: Hiển thị bounding box chứa đối tượng lên video\n",
        "Bước 6: Lăp lại 5 bước trên qua mỗi khung hình để theo dõi đối tượng ở khung hình tiếp theo\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Khởi tạo YOLO và CLIP\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Sử dụng GPU nếu khả dụng, nếu không thì sử dụng CPU.\n",
        "yolo = YOLO(\"yolov8s.pt\")  # Tải mô hình YOLOv8 pre-trained từ file \"yolov8s.pt\".\n",
        "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)  # Tải mô hình CLIP pre-trained.\n",
        "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")  # Bộ xử lý dữ liệu cho CLIP.\n",
        "\n",
        "# Hàm phát hiện và theo dõi đối tượng\n",
        "def detect_and_track(video_path, text_description, output_path=\"output_video.mp4\", similarity_threshold=0.2):\n",
        "    \"\"\"\n",
        "    Goal: Phát hiện và theo dõi đối tượng trong video, so sánh với mô tả văn bản,\n",
        "          vẽ bounding box lên đối tượng nếu độ tương đồng lớn hơn ngưỡng.\n",
        "\n",
        "    Input:\n",
        "    - video_path (str): Đường dẫn đến video đầu vào.\n",
        "    - text_description (str): Mô tả văn bản của đối tượng cần phát hiện trong video.\n",
        "    - output_path (str): Đường dẫn để lưu video đầu ra (mặc định \"output_video.mp4\").\n",
        "    - similarity_threshold (float): Ngưỡng độ tương đồng cosine giữa đối tượng và mô tả (mặc định 0.2).\n",
        "\n",
        "    Output:\n",
        "    - Video đầu ra sẽ được lưu tại output_path, với các đối tượng có độ tương đồng cao với mô tả được đánh dấu bằng bounding box.\n",
        "    - Video đã được xử lý sẽ tự động tải xuống máy tính của người dùng.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        cap = cv2.VideoCapture(video_path)  # Mở video từ đường dẫn.\n",
        "        if not cap.isOpened():  # Kiểm tra nếu không mở được video.\n",
        "            raise Exception(\"Không thể mở video. Kiểm tra đường dẫn video.\")\n",
        "\n",
        "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # Lấy chiều rộng của khung hình video.\n",
        "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # Lấy chiều cao của khung hình video.\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))  # Lấy số khung hình mỗi giây (FPS).\n",
        "        out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
        "        # Khởi tạo đối tượng ghi video đầu ra.\n",
        "\n",
        "        frame_index = 0  # Biến đếm số khung hình đã xử lý.\n",
        "        while cap.isOpened():  # Lặp qua các khung hình của video.\n",
        "            \"\"\"\n",
        "            Bước 1: Lấy từng khung hình trong video\n",
        "            \"\"\"\n",
        "            ret, frame = cap.read()  # Đọc một khung hình từ video.\n",
        "            if not ret:  # Dừng vòng lặp nếu không còn khung hình.\n",
        "                break\n",
        "            if frame_index % 3 != 0:  # Chỉ xử lý mỗi khung hình thứ 3 để giảm tải xử lý.\n",
        "                frame_index += 1\n",
        "                continue\n",
        "            frame_index += 1\n",
        "            \"\"\"\n",
        "            Bước 2: Phát hiện các đối tượng trong khung hình bằng YOLOv8\n",
        "            \"\"\"\n",
        "            frame = cv2.convertScaleAbs(frame, alpha=1.5, beta=20)\n",
        "            # Tăng độ sáng và độ tương phản của khung hình.\n",
        "            pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "            # Chuyển khung hình từ định dạng OpenCV (BGR) sang định dạng PIL (RGB).\n",
        "            results = yolo(frame)  # Phát hiện đối tượng trong khung hình bằng YOLO.\n",
        "            if len(results[0].boxes) == 0:  # Nếu không phát hiện được đối tượng, bỏ qua khung hình này.\n",
        "                continue\n",
        "\n",
        "            boxes = results[0].boxes.xyxy.cpu().numpy()  # Lấy toạ độ các bounding box dưới dạng mảng NumPy.\n",
        "            scores = results[0].boxes.conf.cpu().numpy()  # Lấy các giá trị độ tin cậy (confidence scores).\n",
        "            \"\"\"\n",
        "            Bước 3: Kết hợp các đối tượng đã phát hiện ở bước 2 với mô tả ngôn ngữ tự nhiên bằng CLIP\n",
        "            \"\"\"\n",
        "            # Tính đặc trưng của mô tả văn bản bằng CLIP.\n",
        "            inputs_text = clip_processor(text=[text_description], images=None, return_tensors=\"pt\", padding=True).to(device)\n",
        "            text_features = clip_model.get_text_features(**inputs_text)  # Đặc trưng vector của văn bản.\n",
        "\n",
        "            max_similarity = -1  # Biến lưu độ tương đồng lớn nhất giữa đối tượng và mô tả văn bản.\n",
        "            best_box = None  # Biến lưu bounding box tốt nhất.\n",
        "            for i, box in enumerate(boxes):  # Lặp qua các bounding box được phát hiện.\n",
        "                if scores[i] < 0.5:  # Bỏ qua các bounding box có độ tin cậy nhỏ hơn 0.5.\n",
        "                    continue\n",
        "                x1, y1, x2, y2 = map(int, box)  # Chuyển đổi toạ độ bounding box sang số nguyên.\n",
        "                cropped_img = pil_image.crop((x1, y1, x2, y2))  # Cắt ảnh đối tượng từ khung hình.\n",
        "                inputs_image = clip_processor(images=cropped_img, text=None, return_tensors=\"pt\").to(device)\n",
        "                # Tính đặc trưng vector của ảnh đối tượng.\n",
        "                image_features = clip_model.get_image_features(**inputs_image)\n",
        "                similarity = torch.cosine_similarity(text_features, image_features).item()\n",
        "                # Tính độ tương đồng cosine giữa văn bản và ảnh.\n",
        "                \"\"\"\n",
        "                  Bước 4: Chọn đối tượng có độ tương thích cao nhất\n",
        "                \"\"\"\n",
        "                if similarity > max_similarity and similarity > similarity_threshold:\n",
        "                    # Cập nhật bounding box tốt nhất nếu độ tương đồng lớn hơn ngưỡng.\n",
        "                    max_similarity = similarity\n",
        "                    best_box = (x1, y1, x2, y2)\n",
        "                \"\"\"\n",
        "                Bước 5: Hiển thị bounding box chứa đối tượng lên video\n",
        "                \"\"\"\n",
        "            if best_box:  # Nếu tìm thấy đối tượng phù hợp.\n",
        "                x1, y1, x2, y2 = best_box\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                # Vẽ bounding box lên khung hình.\n",
        "                cv2.putText(frame, f\"{text_description} ({max_similarity:.2f})\", (x1, y1 - 10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "                # Hiển thị mô tả đối tượng và độ tương đồng lên khung hình.\n",
        "\n",
        "            out.write(frame)  # Ghi khung hình đã xử lý vào file video đầu ra.\n",
        "\n",
        "        cap.release()  # Đóng video đầu vào.\n",
        "        out.release()  # Đóng video đầu ra.\n",
        "        print(f\"Video đã được lưu tại {output_path}\")\n",
        "\n",
        "        # Tự động tải file xuống máy tính.\n",
        "        files.download(output_path)\n",
        "\n",
        "    except Exception as e:  # Bắt lỗi trong quá trình xử lý.\n",
        "        print(f\"Lỗi: {e}\")\n",
        "\n",
        "# Hàm tải file video lên\n",
        "def upload_video():\n",
        "    \"\"\"\n",
        "    Goal: Cung cấp giao diện để người dùng tải video lên Google Colab.\n",
        "\n",
        "    Input:\n",
        "    - Không có tham số đầu vào.\n",
        "\n",
        "    Output:\n",
        "    - file_path (str): Đường dẫn tới file video đã tải lên trong môi trường Google Colab.\n",
        "    \"\"\"\n",
        "    print(\"Vui lòng tải lên một video.\")\n",
        "    uploaded = files.upload()  # Hiển thị giao diện tải file lên trong Google Colab.\n",
        "\n",
        "    # Lấy file đầu tiên trong danh sách file đã tải.\n",
        "    for filename in uploaded.keys():\n",
        "        file_path = f\"/content/{filename}\"  # Đường dẫn lưu file trong môi trường Colab.\n",
        "        with open(file_path, \"wb\") as f:  # Lưu nội dung file.\n",
        "            f.write(uploaded[filename])\n",
        "        print(f\"File {filename} đã được lưu tại: {file_path}\")\n",
        "        return file_path  # Trả về đường dẫn file.\n",
        "\n",
        "# Giao diện đầu vào từ người dùng\n",
        "def create_interface():\n",
        "    \"\"\"\n",
        "    Goal: Cung cấp giao diện người dùng để tải video lên, nhập mô tả đối tượng và gọi hàm xử lý video.\n",
        "\n",
        "    Input:\n",
        "    - Không có tham số đầu vào.\n",
        "\n",
        "    Output:\n",
        "    - Gọi hàm detect_and_track để xử lý video với mô tả đối tượng đã nhập.\n",
        "    \"\"\"\n",
        "    video_path = upload_video()  # Yêu cầu người dùng tải video lên.\n",
        "    text_description = input(\"Nhập mô tả đối tượng \")  # Yêu cầu người dùng nhập mô tả đối tượng.\n",
        "    output_path = \"output_video.mp4\"  # Đường dẫn lưu video đầu ra.\n",
        "\n",
        "    if not text_description.strip():  # Kiểm tra nếu người dùng không nhập mô tả.\n",
        "        print(\"Vui lòng nhập mô tả đối tượng.\")\n",
        "    else:\n",
        "        detect_and_track(video_path, text_description, output_path)  # Gọi hàm xử lý.\n",
        "\n",
        "# Chạy giao diện\n",
        "create_interface()  # Bắt đầu chương trình.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "091c1dfd56994c23aab32a4a254aab2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c06ecd69377459383b5f0ba65d574a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11cbc9d4a02a43f298b547caba151d95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_217500d7b5b040c5a3d8898f99b9e4bb",
            "placeholder": "​",
            "style": "IPY_MODEL_fe9e7c997970480bbaf38c693daf828f",
            "value": " 862k/862k [00:00&lt;00:00, 12.0MB/s]"
          }
        },
        "14e361b595394ae6b8a34d094fa26cd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "169107a648684c4f8836dd33cf12b512": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "170e9dcda6b348748a8026ae60339ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe8e636a776d41a0a5d99e8e42a611a0",
            "placeholder": "​",
            "style": "IPY_MODEL_d81aaf4c93dc491eabe17b56fecb377d",
            "value": "merges.txt: 100%"
          }
        },
        "18cb6236cfaa4dd4ab4ac583a09ce09a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bd51c0cae8740f692b1b43c0f60dd6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80cf565cf4d3450db82b429c159e8909",
            "placeholder": "​",
            "style": "IPY_MODEL_d660a580bc724763aa6c776ee602169b",
            "value": "config.json: 100%"
          }
        },
        "1e9793c081044d8cb72a3c7691d1d2c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "215c4881f20f444db4be5e43fe1b5ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "217500d7b5b040c5a3d8898f99b9e4bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2309eea25da9474c876efebc14b4a767": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "239c9ab6a9d74c92a87d16ca9c82fade": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2451169792da4c9ea22694bbd98041a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2910fd85232e4cb1bdfb9cd23f1b8c75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d7372bce5f44c4ea798804c7bf49315": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2910fd85232e4cb1bdfb9cd23f1b8c75",
            "max": 524657,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_813e3b5fcc3244b18d9bf79b38cd26d2",
            "value": 524657
          }
        },
        "2e7eaa35d6254c4a96cc88f560c2075b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "383c875985794aad97e9bbc28a3b467c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a783e0967194f62a92be1d9b387e275": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3beef3208daf4a859faa28e2323f612a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b019145b970d4bb690fd66e2c753630a",
              "IPY_MODEL_ec2a9201474f49ac941266497c532b76",
              "IPY_MODEL_d61d96bd8e064d86b9fd4f6fb2af5013"
            ],
            "layout": "IPY_MODEL_ab96e57dc414434fb417779b63cad442"
          }
        },
        "3d8993954a8349dc85a9268bc5b1aa0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18cb6236cfaa4dd4ab4ac583a09ce09a",
            "placeholder": "​",
            "style": "IPY_MODEL_169107a648684c4f8836dd33cf12b512",
            "value": " 389/389 [00:00&lt;00:00, 21.9kB/s]"
          }
        },
        "3e7d467e6e6b4dd391e2a0a3a64e26b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e6c7c2900db4635bcbddaea6284e3b2",
              "IPY_MODEL_ba312a1c56dd4cc1aec27c654d2b97f8",
              "IPY_MODEL_92f1956248bc439398785445a82a50ab"
            ],
            "layout": "IPY_MODEL_0c06ecd69377459383b5f0ba65d574a8"
          }
        },
        "3f10a267ccaa407e98af0afc4c6dfb56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f2118fac97e4159ab8a7fa0102aca87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65abba2b2fed4982923e477566258b87",
            "placeholder": "​",
            "style": "IPY_MODEL_8197a97e51aa4eb3b4ee9104775ebb78",
            "value": " 4.19k/4.19k [00:00&lt;00:00, 324kB/s]"
          }
        },
        "41cedcecc6ca49f68b54dbe04879e248": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "445439c979564c399826d5d6e64c55c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45ca33753dfd4a0d9ef6621b7782aceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8537fdd5f0d40ecaf767ca660f31937",
            "max": 4186,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf839712ad574fdea64303d416cff76d",
            "value": 4186
          }
        },
        "487a38fb1538444c8d5752aeaa89cb86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90621a42cf504265a6fdfaac997fd67f",
              "IPY_MODEL_6406ba75bdc84135aa784a2e65559030",
              "IPY_MODEL_3d8993954a8349dc85a9268bc5b1aa0a"
            ],
            "layout": "IPY_MODEL_d88c6a1fce1449e0ba5ff2f7118a9656"
          }
        },
        "4df1df4cacc34567981dc0d15b6b2fbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec26ae7fd2bb40d28f1b3fc69f293903",
            "placeholder": "​",
            "style": "IPY_MODEL_1e9793c081044d8cb72a3c7691d1d2c4",
            "value": " 316/316 [00:00&lt;00:00, 16.4kB/s]"
          }
        },
        "4f343239f9114f719e266944b593daa7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "515adf57386b4f9cb6e751da8b05106d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56802f58ce934563bcf84443d12145ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cdfd713baa3d4e4faf39f8b472a4d1fb",
              "IPY_MODEL_7c70b0c9f1224c2e8165502f822dfa2e",
              "IPY_MODEL_11cbc9d4a02a43f298b547caba151d95"
            ],
            "layout": "IPY_MODEL_2451169792da4c9ea22694bbd98041a7"
          }
        },
        "59ad8f216d294aebacbd123f12993540": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70ec960296ed4afdb33dbb89ba511478",
            "placeholder": "​",
            "style": "IPY_MODEL_515adf57386b4f9cb6e751da8b05106d",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "5a21215111cb4dadbe5f6765d6c0b124": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e6c7c2900db4635bcbddaea6284e3b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2f3699799ba4cc9a56d5cd170aceb30",
            "placeholder": "​",
            "style": "IPY_MODEL_445439c979564c399826d5d6e64c55c8",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "5f644ed5b67242a4bf1f3c479ec9ccc1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6406ba75bdc84135aa784a2e65559030": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a21215111cb4dadbe5f6765d6c0b124",
            "max": 389,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14e361b595394ae6b8a34d094fa26cd3",
            "value": 389
          }
        },
        "64d742e82a324d5b9eaa299ff44f6efd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65abba2b2fed4982923e477566258b87": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68b112836aac499eb8e6927984a12c34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a343752a61fc471195863c1fdd442682",
              "IPY_MODEL_94705c701d264e7b8f1eedd7e2b8cb01",
              "IPY_MODEL_9f06a09a916d4b208d77c00f278a2bf1"
            ],
            "layout": "IPY_MODEL_c716da8dcefe42bcbbf61278882bf357"
          }
        },
        "69094fb36a2b498a86e4aa49a3a3b685": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9991cd01e9e46a2b7c3501de24b482a",
            "max": 316,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74a46231c19b4f2a9a58b25361a1bb8d",
            "value": 316
          }
        },
        "6988020cb7574cd5bce9ab423028afa4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6daa2b736c164922aeb678a2108557ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70ec960296ed4afdb33dbb89ba511478": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74a46231c19b4f2a9a58b25361a1bb8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "780ad657c06d4a42b57de668f2755614": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c70b0c9f1224c2e8165502f822dfa2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f343239f9114f719e266944b593daa7",
            "max": 862328,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ccbebac1f03043a28938ae4ea51797f0",
            "value": 862328
          }
        },
        "80cf565cf4d3450db82b429c159e8909": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "813e3b5fcc3244b18d9bf79b38cd26d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8197a97e51aa4eb3b4ee9104775ebb78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8341321f84514545ba0b9b0b57fac6bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8db337d20a8c4925857215a98b98c2e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c63e3001d764411e9df2e7600319f03d",
              "IPY_MODEL_8f60445bed5a4ff29390fc057a496705",
              "IPY_MODEL_ce0ce49a91af4db0961ad9fb7533ed68"
            ],
            "layout": "IPY_MODEL_8341321f84514545ba0b9b0b57fac6bf"
          }
        },
        "8e05dba349854d0e82f2166e58f76e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f60445bed5a4ff29390fc057a496705": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca8d3e199cd946f2b71a2a13798a09a0",
            "max": 2224041,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_215c4881f20f444db4be5e43fe1b5ae4",
            "value": 2224041
          }
        },
        "90621a42cf504265a6fdfaac997fd67f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9fe9ac567784c7d8c93ec9392616fd1",
            "placeholder": "​",
            "style": "IPY_MODEL_f29b5f1a341c4d8998901a27a40bc2fc",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "92f1956248bc439398785445a82a50ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6988020cb7574cd5bce9ab423028afa4",
            "placeholder": "​",
            "style": "IPY_MODEL_a1a27775d5c649a4b8f6a372f8fb538c",
            "value": " 605M/605M [00:02&lt;00:00, 199MB/s]"
          }
        },
        "9442e7e5f7dc4128ba66a2f86d67e411": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94705c701d264e7b8f1eedd7e2b8cb01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64d742e82a324d5b9eaa299ff44f6efd",
            "max": 605157884,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc4d3084afa84f578b37291a3d72efe4",
            "value": 605157884
          }
        },
        "99e6ef8c802f4d7dbf033ee590e04133": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c9b95983a204be6a74892aa4b7c663f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f06a09a916d4b208d77c00f278a2bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99e6ef8c802f4d7dbf033ee590e04133",
            "placeholder": "​",
            "style": "IPY_MODEL_091c1dfd56994c23aab32a4a254aab2a",
            "value": " 605M/605M [00:04&lt;00:00, 199MB/s]"
          }
        },
        "9f1d0c5306554e069cc2c3147f0676b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1a27775d5c649a4b8f6a372f8fb538c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a343752a61fc471195863c1fdd442682": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f644ed5b67242a4bf1f3c479ec9ccc1",
            "placeholder": "​",
            "style": "IPY_MODEL_c06feaa09c0d434b8bdefd02c3a3885a",
            "value": "model.safetensors: 100%"
          }
        },
        "a9991cd01e9e46a2b7c3501de24b482a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab96e57dc414434fb417779b63cad442": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b013c13fccd44f408a86547d866dc463": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b019145b970d4bb690fd66e2c753630a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f10a267ccaa407e98af0afc4c6dfb56",
            "placeholder": "​",
            "style": "IPY_MODEL_41cedcecc6ca49f68b54dbe04879e248",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b2f3699799ba4cc9a56d5cd170aceb30": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba312a1c56dd4cc1aec27c654d2b97f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e7eaa35d6254c4a96cc88f560c2075b",
            "max": 605247071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e05dba349854d0e82f2166e58f76e82",
            "value": 605247071
          }
        },
        "bc4d3084afa84f578b37291a3d72efe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf839712ad574fdea64303d416cff76d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c06feaa09c0d434b8bdefd02c3a3885a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c63e3001d764411e9df2e7600319f03d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_780ad657c06d4a42b57de668f2755614",
            "placeholder": "​",
            "style": "IPY_MODEL_f000113c2f264fffb570b1b69c499425",
            "value": "tokenizer.json: 100%"
          }
        },
        "c716da8dcefe42bcbbf61278882bf357": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7701691ea354612a2dd5cce446d62ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_170e9dcda6b348748a8026ae60339ea2",
              "IPY_MODEL_2d7372bce5f44c4ea798804c7bf49315",
              "IPY_MODEL_dc5b0aea26f54226b5fde49d40b1cdb3"
            ],
            "layout": "IPY_MODEL_b013c13fccd44f408a86547d866dc463"
          }
        },
        "c8537fdd5f0d40ecaf767ca660f31937": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca8d3e199cd946f2b71a2a13798a09a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccbebac1f03043a28938ae4ea51797f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cdfd713baa3d4e4faf39f8b472a4d1fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6daa2b736c164922aeb678a2108557ae",
            "placeholder": "​",
            "style": "IPY_MODEL_3a783e0967194f62a92be1d9b387e275",
            "value": "vocab.json: 100%"
          }
        },
        "ce0ce49a91af4db0961ad9fb7533ed68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_239c9ab6a9d74c92a87d16ca9c82fade",
            "placeholder": "​",
            "style": "IPY_MODEL_9c9b95983a204be6a74892aa4b7c663f",
            "value": " 2.22M/2.22M [00:00&lt;00:00, 28.4MB/s]"
          }
        },
        "d1ebd4bcd34242ccbc510d78b865144f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1bd51c0cae8740f692b1b43c0f60dd6e",
              "IPY_MODEL_45ca33753dfd4a0d9ef6621b7782aceb",
              "IPY_MODEL_3f2118fac97e4159ab8a7fa0102aca87"
            ],
            "layout": "IPY_MODEL_dbf354bbbff3406c9a98ad69909544ab"
          }
        },
        "d61d96bd8e064d86b9fd4f6fb2af5013": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9442e7e5f7dc4128ba66a2f86d67e411",
            "placeholder": "​",
            "style": "IPY_MODEL_eb68b90822724eaba381eaf9fb9459dd",
            "value": " 592/592 [00:00&lt;00:00, 24.5kB/s]"
          }
        },
        "d660a580bc724763aa6c776ee602169b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d81aaf4c93dc491eabe17b56fecb377d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d88c6a1fce1449e0ba5ff2f7118a9656": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db94d541b390493a9119cd946e1cb94d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59ad8f216d294aebacbd123f12993540",
              "IPY_MODEL_69094fb36a2b498a86e4aa49a3a3b685",
              "IPY_MODEL_4df1df4cacc34567981dc0d15b6b2fbe"
            ],
            "layout": "IPY_MODEL_2309eea25da9474c876efebc14b4a767"
          }
        },
        "dbf354bbbff3406c9a98ad69909544ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc5b0aea26f54226b5fde49d40b1cdb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_383c875985794aad97e9bbc28a3b467c",
            "placeholder": "​",
            "style": "IPY_MODEL_ec2883482a9a4b1d987b7d655b4980ce",
            "value": " 525k/525k [00:00&lt;00:00, 23.0MB/s]"
          }
        },
        "e116fd27008c4b44aef610d8eaf388f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9fe9ac567784c7d8c93ec9392616fd1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb68b90822724eaba381eaf9fb9459dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec26ae7fd2bb40d28f1b3fc69f293903": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec2883482a9a4b1d987b7d655b4980ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec2a9201474f49ac941266497c532b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f1d0c5306554e069cc2c3147f0676b8",
            "max": 592,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e116fd27008c4b44aef610d8eaf388f3",
            "value": 592
          }
        },
        "f000113c2f264fffb570b1b69c499425": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f29b5f1a341c4d8998901a27a40bc2fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe8e636a776d41a0a5d99e8e42a611a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe9e7c997970480bbaf38c693daf828f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}